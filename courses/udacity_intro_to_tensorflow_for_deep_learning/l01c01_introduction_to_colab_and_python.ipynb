{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ---------- CELL 1: Install & Preflight ----------\n",
        "# Run this first. It installs cloudflared and Python libs.\n",
        "# It may take a few minutes (model downloads happen in later cell).\n",
        "\n",
        "# System packages + cloudflared\n",
        "!apt-get update -qq\n",
        "!apt-get install -y -qq wget ca-certificates ffmpeg fonts-noto\n",
        "\n",
        "# Download and install cloudflared (auto tunnel)\n",
        "!wget -q -O /tmp/cloudflared.deb \"https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\"\n",
        "!dpkg -i /tmp/cloudflared.deb || true\n",
        "!apt-get -f install -y -qq\n",
        "\n",
        "# Python packages (transformers may be large)\n",
        "!pip install -q yt-dlp moviepy==1.0.3 ffmpeg-python transformers[torch] accelerate sentencepiece soundfile gTTS flask\n",
        "\n",
        "# Try installing Bark (optional, better TTS). If it fails, code will fallback to gTTS.\n",
        "try:\n",
        "    !pip install -q git+https://github.com/suno-ai/bark.git\n",
        "except Exception as e:\n",
        "    print(\"Bark install attempt failed (no problem - gTTS fallback will be used).\", e)\n",
        "\n",
        "# Quick checks\n",
        "import sys, torch\n",
        "print(\"Python:\", sys.version.split()[0])\n",
        "print(\"Torch:\", getattr(torch, \"__version__\", \"not installed\"))\n",
        "print(\"GPU available:\", torch.cuda.is_available())\n",
        "\n",
        "# Create output folder\n",
        "import os\n",
        "os.makedirs('/content/auto_videos', exist_ok=True)\n",
        "print(\"Output directory:\", \"/content/auto_videos\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzcTQnpP8aVB",
        "outputId": "ed7be79f-9d38-4873-f475-e3d5156ce5b9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "(Reading database ... 127572 files and directories currently installed.)\n",
            "Preparing to unpack /tmp/cloudflared.deb ...\n",
            "Unpacking cloudflared (2025.10.1) over (2025.10.1) ...\n",
            "Setting up cloudflared (2025.10.1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Python: 3.12.12\n",
            "Torch: 2.8.0+cu126\n",
            "GPU available: True\n",
            "Output directory: /content/auto_videos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- CELL 2 (REPLACE previous): Production Queue Server (TEXT-ONLY) + cloudflared ----------\n",
        "# Paste & run this in Notebook A (replace old CELL 2). This version returns text facts only.\n",
        "\n",
        "import os, time, uuid, json, subprocess, threading, queue, re\n",
        "from flask import Flask, request, jsonify\n",
        "\n",
        "# ---------- CONFIG ----------\n",
        "OUTPUT_DIR = \"/content/auto_videos\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "PORT = 5000\n",
        "\n",
        "# Simple in-memory queue and jobs store\n",
        "job_q = queue.Queue()\n",
        "jobs = {}\n",
        "\n",
        "# ---------- Simple text fact generator (replaceable) ----------\n",
        "def generate_fact(topic):\n",
        "    # Temporary deterministic facts ‚Äî later we'll swap with Groq-based function\n",
        "    facts = [\n",
        "        f\"Overthinking makes your brain treat mere thoughts like real threats.\",\n",
        "        f\"People who overthink often get decision paralysis from fearing the worst outcome.\",\n",
        "        f\"Overthinking commonly disrupts sleep and drains emotional energy.\"\n",
        "    ]\n",
        "    # return a list of strings\n",
        "    return facts\n",
        "\n",
        "# ---------- Worker (TEXT ONLY) ----------\n",
        "def worker_text_only():\n",
        "    while True:\n",
        "        jobid, topic = job_q.get()\n",
        "        try:\n",
        "            jobs[jobid]['status'] = 'running'\n",
        "            print(f\"üîß Worker processing job {jobid} ‚Äî topic: {topic}\")\n",
        "\n",
        "            # Generate text-only output\n",
        "            result = generate_fact(topic)\n",
        "            # Save result & mark done\n",
        "            jobs[jobid]['result'] = result\n",
        "            jobs[jobid]['status'] = 'done'\n",
        "            jobs[jobid]['finished'] = time.time()\n",
        "\n",
        "            print(f\"‚úÖ Job {jobid} done ‚Äî result ready.\")\n",
        "        except Exception as e:\n",
        "            jobs[jobid]['status'] = 'error'\n",
        "            jobs[jobid]['error'] = str(e)\n",
        "            print(f\"‚ùå Error processing job {jobid}: {e}\")\n",
        "        finally:\n",
        "            job_q.task_done()\n",
        "\n",
        "# Start the single worker thread (daemon)\n",
        "threading.Thread(target=worker_text_only, daemon=True).start()\n",
        "\n",
        "# ---------- Flask app: enqueue + status endpoints ----------\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route(\"/generate\", methods=[\"POST\"])\n",
        "def enqueue():\n",
        "    data = request.get_json(force=True, silent=True) or {}\n",
        "    topic = data.get('topic','creepy facts')\n",
        "    jobid = str(uuid.uuid4())[:8]\n",
        "    jobs[jobid] = {\n",
        "        \"status\":\"queued\",\n",
        "        \"topic\":topic,\n",
        "        \"created\": time.time()\n",
        "    }\n",
        "    job_q.put((jobid, topic))\n",
        "    return jsonify({\"status\":\"queued\",\"jobid\":jobid,\"poll\":f\"/status/{jobid}\"})\n",
        "\n",
        "@app.route(\"/status/<jobid>\", methods=[\"GET\"])\n",
        "def status(jobid):\n",
        "    info = jobs.get(jobid)\n",
        "    if not info:\n",
        "        return jsonify({\"error\":\"unknown jobid\"}), 404\n",
        "    return jsonify(info)\n",
        "\n",
        "@app.route(\"/\", methods=[\"GET\"])\n",
        "def root():\n",
        "    return jsonify({\"status\":\"alive\",\"info\":\"Production queue API. POST /generate with {'topic':'...'}\"})\n",
        "\n",
        "# ---------- Start cloudflared tunnel (prints public URL) ----------\n",
        "def start_cloudflared_and_print():\n",
        "    cmd = [\"cloudflared\", \"tunnel\", \"--url\", f\"http://localhost:{PORT}\"]\n",
        "    popen = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "    public_url = None\n",
        "    for _ in range(400):\n",
        "        line = popen.stdout.readline()\n",
        "        if not line:\n",
        "            time.sleep(0.1)\n",
        "            continue\n",
        "        print(line.strip())\n",
        "        if \"trycloudflare.com\" in line or \"trycloudflare\" in line:\n",
        "            m = re.search(r'(https?://[^\\s]+trycloudflare[^\\s]*)', line)\n",
        "            public_url = m.group(1) if m else line.strip()\n",
        "            print(\"\\n‚úÖ PUBLIC URL:\", public_url)\n",
        "            print(\"Use this to POST /generate and GET /status/<jobid>\\n\")\n",
        "            break\n",
        "\n",
        "# Run Flask app and cloudflared in threads\n",
        "def start_flask():\n",
        "    app.run(host='0.0.0.0', port=PORT)\n",
        "\n",
        "threading.Thread(target=start_flask, daemon=True).start()\n",
        "time.sleep(1)\n",
        "threading.Thread(target=start_cloudflared_and_print, daemon=True).start()\n",
        "\n",
        "print(\"‚úÖ TEXT-ONLY production queue server started. POST /generate to queue jobs.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EV6R2MkX8peS",
        "outputId": "72571fb1-cddd-4d67-fa83-ce24f42d90db"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:5000\n",
            " * Running on http://172.28.0.12:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ TEXT-ONLY production queue server started. POST /generate to queue jobs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- CELL: Upgrade worker -> Full Video w/ Bark TTS + Ambient Music (Dark ambient A) ----------\n",
        "# Paste & run in Notebook A (replaces previous video worker). Keep the notebook open.\n",
        "\n",
        "import os, time, uuid, json, subprocess, threading, queue, re\n",
        "from flask import Flask, request, jsonify, send_file\n",
        "from moviepy.editor import VideoFileClip, AudioFileClip, CompositeVideoClip, concatenate_videoclips, ColorClip, ImageClip, CompositeAudioClip, afx\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "\n",
        "# CONFIG\n",
        "OUTPUT_DIR = \"/content/auto_videos\"\n",
        "AUDIO_DIR = os.path.join(OUTPUT_DIR, \"audio\")\n",
        "os.makedirs(AUDIO_DIR, exist_ok=True)\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "PORT = 5000\n",
        "WIDTH, HEIGHT, FPS = 1080, 1920, 25\n",
        "FACTS_COUNT = 5\n",
        "USERNAME_WM = os.getenv(\"USERNAME_WM\", \"darktruths.hub007\")\n",
        "BARK_VOICE = \"v2/en_speaker_9\"   # deep male documentary\n",
        "MUSIC_SEARCH_QUERY = \"dark ambient background music creative commons\"\n",
        "MUSIC_MAX_SECONDS = 200\n",
        "\n",
        "# Ensure Bark available flag\n",
        "BARK_AVAILABLE = False\n",
        "try:\n",
        "    from bark import generate_audio, preload_models, SAMPLE_RATE\n",
        "    try:\n",
        "        print(\"Preloading Bark models (may download tens to hundreds MB).\")\n",
        "        preload_models()\n",
        "    except Exception as e:\n",
        "        print(\"Bark preload warning:\", e)\n",
        "    BARK_AVAILABLE = True\n",
        "    print(\"Bark is available and will be used for TTS.\")\n",
        "except Exception as e:\n",
        "    print(\"Bark not available, will try to fall back to gTTS if necessary.\", e)\n",
        "    BARK_AVAILABLE = False\n",
        "\n",
        "# Safe generate_facts: use existing function if present, else fallback simple generator\n",
        "def safe_generate_facts(topic, n=FACTS_COUNT):\n",
        "    try:\n",
        "        # if a user-defined generate_facts exists, call it\n",
        "        gf = globals().get(\"generate_facts\", None)\n",
        "        if callable(gf):\n",
        "            out = gf(topic, n=n)\n",
        "            if isinstance(out, list) and len(out) >= 1:\n",
        "                return out[:n]\n",
        "    except Exception as e:\n",
        "        print(\"Existing generate_facts() raised:\", e)\n",
        "    # fallback simple facts\n",
        "    facts = []\n",
        "    for i in range(n):\n",
        "        facts.append(f\"Fact {i+1} about {topic}.\")\n",
        "    return facts\n",
        "\n",
        "# ---- Bark TTS helper (write wav) ----\n",
        "def synthesize_bark_to_wav(text, out_wav_path, voice=BARK_VOICE):\n",
        "    try:\n",
        "        # generate_audio returns numpy array or list of floats\n",
        "        wav = generate_audio(text=text, history_prompt=voice)\n",
        "        # ensure numpy array\n",
        "        arr = np.array(wav)\n",
        "        sf.write(out_wav_path, arr, SAMPLE_RATE)\n",
        "        return out_wav_path\n",
        "    except Exception as e:\n",
        "        print(\"Bark synth error:\", e)\n",
        "        return None\n",
        "\n",
        "# convert wav to mp3 (ffmpeg must be installed in Colab)\n",
        "def wav_to_mp3(wav_path, mp3_path):\n",
        "    try:\n",
        "        cmd = [\"ffmpeg\", \"-y\", \"-i\", wav_path, \"-codec:a\", \"libmp3lame\", \"-qscale:a\", \"2\", mp3_path]\n",
        "        subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "        return mp3_path\n",
        "    except Exception as e:\n",
        "        print(\"ffmpeg convert error:\", e)\n",
        "        return None\n",
        "\n",
        "# ---- Download a single ambient music track (yt-dlp search for CC) ----\n",
        "def download_ambient_music(query=MUSIC_SEARCH_QUERY):\n",
        "    try:\n",
        "        out_template = os.path.join(OUTPUT_DIR, \"ambient_%(id)s.%(ext)s\")\n",
        "        cmd = [\n",
        "            \"yt-dlp\",\n",
        "            f\"ytsearch1:{query}\",\n",
        "            \"--no-playlist\",\n",
        "            \"--restrict-filenames\",\n",
        "            \"--format\", \"bestaudio\",\n",
        "            \"--output\", out_template\n",
        "        ]\n",
        "        subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "        # find downloaded file\n",
        "        candidates = sorted([os.path.join(OUTPUT_DIR,f) for f in os.listdir(OUTPUT_DIR) if f.startswith(\"ambient_\")])\n",
        "        if not candidates:\n",
        "            return None\n",
        "        music_file = candidates[-1]\n",
        "        # trim large file to MUSIC_MAX_SECONDS seconds to speed up\n",
        "        trimmed = music_file.replace(\".webm\", \"_trim.mp3\").replace(\".m4a\", \"_trim.mp3\").replace(\".mp3\",\"_trim.mp3\")\n",
        "        # use ffmpeg to trim\n",
        "        cmd2 = [\"ffmpeg\", \"-y\", \"-i\", music_file, \"-t\", str(MUSIC_MAX_SECONDS), \"-vn\", \"-acodec\", \"libmp3lame\", \"-qscale:a\", \"4\", trimmed]\n",
        "        subprocess.run(cmd2, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "        return trimmed if os.path.exists(trimmed) else music_file\n",
        "    except Exception as e:\n",
        "        print(\"Ambient music download failed:\", e)\n",
        "        return None\n",
        "\n",
        "# ---- Create text image using PIL (avoids ImageMagick) ----\n",
        "def render_text_image(text, out_image_path, width=WIDTH, padding=80, font_size=64):\n",
        "    # choose font (DejaVuSans included in Colab)\n",
        "    try:\n",
        "        font = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\", font_size)\n",
        "    except:\n",
        "        font = ImageFont.load_default()\n",
        "    # wrap text manually\n",
        "    img = Image.new(\"RGBA\", (width, 600), (0,0,0,0))\n",
        "    draw = ImageDraw.Draw(img)\n",
        "    # split into lines\n",
        "    words = text.split()\n",
        "    lines = []\n",
        "    cur = \"\"\n",
        "    for w in words:\n",
        "        test = (cur + \" \" + w).strip()\n",
        "        wsize = draw.textsize(test, font=font)[0]\n",
        "        if wsize > (width - 2*padding):\n",
        "            lines.append(cur)\n",
        "            cur = w\n",
        "        else:\n",
        "            cur = test\n",
        "    if cur:\n",
        "        lines.append(cur)\n",
        "    # compute height\n",
        "bbox = draw.textbbox((0, 0), \"Ay\", font=font)\n",
        "line_h = (bbox[3] - bbox[1]) + 10   # height + padding\n",
        "\n",
        "img_h = padding + line_h * len(lines) + padding\n",
        "img = Image.new(\"RGBA\", (width, max(img_h, 240)), (0,0,0,0))\n",
        "draw = ImageDraw.Draw(img)\n",
        "\n",
        "y = padding // 2\n",
        "for line in lines:\n",
        "    bbox = draw.textbbox((0, 0), line, font=font)\n",
        "    w = bbox[2] - bbox[0]\n",
        "    h = bbox[3] - bbox[1]\n",
        "    draw.text(((width - w) // 2, y), line, font=font, fill=(255,255,255,255))\n",
        "    y += line_h\n",
        "\n",
        "img.save(out_image_path)\n",
        "return out_image_path\n",
        "\n",
        "# ---- Build final vertical clip, per-fact audio sync ----\n",
        "def build_vertical_video_v2(facts, voice_mp3_files, broll_clips, out_path, username=USERNAME_WM):\n",
        "    clips = []\n",
        "    audio_clips = []\n",
        "    music_clip = None\n",
        "    # load background music if present\n",
        "    music_path = download_ambient_music()\n",
        "    if music_path:\n",
        "        try:\n",
        "            music_clip = AudioFileClip(music_path).subclip(0, 9999)\n",
        "            music_clip = music_clip.fx(afx.audio_fadein, 0.5).volumex(0.15)\n",
        "        except Exception as e:\n",
        "            print(\"music load err:\", e)\n",
        "            music_clip = None\n",
        "\n",
        "    for idx, fact in enumerate(facts):\n",
        "        # choose b-roll clip or fallback color\n",
        "        bg = None\n",
        "        if broll_clips and len(broll_clips) > idx:\n",
        "            try:\n",
        "                vc = VideoFileClip(broll_clips[idx]).resize(height=HEIGHT)\n",
        "                if vc.w < WIDTH:\n",
        "                    vc = vc.resize(width=WIDTH)\n",
        "                clip_dur = AudioFileClip(voice_mp3_files[idx]).duration\n",
        "                vc = vc.subclip(0, min(clip_dur + 0.5, vc.duration)).set_duration(clip_dur + 0.5)\n",
        "                bg = vc\n",
        "            except Exception as e:\n",
        "                print(\"bg clip load err:\", e)\n",
        "        if bg is None:\n",
        "            bg = ColorClip((WIDTH, HEIGHT), color=(10,10,12)).set_duration(AudioFileClip(voice_mp3_files[idx]).duration + 0.5)\n",
        "\n",
        "        # render text image and make ImageClip\n",
        "        imgfile = os.path.join(OUTPUT_DIR, f\"text_{uuid.uuid4().hex[:6]}_{idx}.png\")\n",
        "        render_text_image(fact, imgfile, width=WIDTH, font_size=56)\n",
        "        txt_clip = ImageClip(imgfile).set_duration(AudioFileClip(voice_mp3_files[idx]).duration + 0.5).set_position((\"center\", int(HEIGHT*0.12)))\n",
        "\n",
        "        # voice audio\n",
        "        aclip = AudioFileClip(voice_mp3_files[idx])\n",
        "        # mix music (if available) with voice: voice louder, music low\n",
        "        if music_clip:\n",
        "            # create a music subclip matching aclip.duration and reduce volume\n",
        "            try:\n",
        "                music_sub = music_clip.subclip(0, aclip.duration).volumex(0.12)\n",
        "                combined_audio = CompositeAudioClip([music_sub, aclip])\n",
        "            except Exception as e:\n",
        "                print(\"music combine err:\", e)\n",
        "                combined_audio = aclip\n",
        "        else:\n",
        "            combined_audio = aclip\n",
        "\n",
        "        clip = CompositeVideoClip([bg, txt_clip], size=(WIDTH, HEIGHT)).set_duration(aclips := aclip.duration + 0.5)\n",
        "        clip = clip.set_audio(combined_audio)\n",
        "        clips.append(clip)\n",
        "\n",
        "    # concatenate and write file\n",
        "    if not clips:\n",
        "        raise RuntimeError(\"No clips generated\")\n",
        "    final = concatenate_videoclips(clips, method=\"compose\")\n",
        "    # add watermark as final overlay\n",
        "    try:\n",
        "        wm = ImageClip(render_text_image(username, os.path.join(OUTPUT_DIR,\"wm.png\"), width=600, font_size=28)).set_duration(final.duration).set_position((\"right\", \"bottom\")).set_opacity(0.85)\n",
        "        final = CompositeVideoClip([final, wm])\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    final.write_videofile(out_path, fps=FPS, codec=\"libx264\", audio_codec=\"aac\", threads=4)\n",
        "    # cleanup small temp files maybe\n",
        "    return out_path\n",
        "\n",
        "# ---- Helper: download small set of b-roll clips (1 per fact) using yt-dlp (may return fewer) ----\n",
        "def download_brolls_for_topic(topic, count=FACTS_COUNT, max_seconds=8):\n",
        "    clips = []\n",
        "    for q in [f\"{topic} cinematic\", \"dark cinematic fog\", \"abandoned building cinematic\"]:\n",
        "        try:\n",
        "            out_template = os.path.join(OUTPUT_DIR, \"ytclip_%(id)s.%(ext)s\")\n",
        "            cmd = [\n",
        "                \"yt-dlp\",\n",
        "                f\"ytsearch1:{q} creative commons\",\n",
        "                \"--no-playlist\",\n",
        "                \"--restrict-filenames\",\n",
        "                \"--format\", \"mp4\",\n",
        "                \"--output\", out_template\n",
        "            ]\n",
        "            subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "            # find latest matching file\n",
        "            candidates = sorted([os.path.join(OUTPUT_DIR,f) for f in os.listdir(OUTPUT_DIR) if f.startswith(\"ytclip_\") and f.endswith(\".mp4\")])\n",
        "            if candidates:\n",
        "                fpath = candidates[-1]\n",
        "                # trim\n",
        "                trimmed = fpath.replace(\".mp4\", \"_trim.mp4\")\n",
        "                clip = VideoFileClip(fpath)\n",
        "                dur = min(max_seconds, clip.duration)\n",
        "                clip.subclip(0, dur).write_videofile(trimmed, fps=FPS, codec=\"libx264\", audio_codec=\"aac\", threads=2, verbose=False, logger=None)\n",
        "                clip.close()\n",
        "                clips.append(trimmed)\n",
        "            if len(clips) >= count:\n",
        "                break\n",
        "        except Exception as e:\n",
        "            print(\"broll fetch error:\", e)\n",
        "            continue\n",
        "    return clips\n",
        "\n",
        "# ---- Worker: full pipeline (facts -> per-fact bark mp3 -> b-roll -> final video) ----\n",
        "job_q = queue.Queue()\n",
        "jobs = {}  # jobid -> info\n",
        "\n",
        "def full_worker():\n",
        "    while True:\n",
        "        jobid, topic = job_q.get()\n",
        "        jobs[jobid]['status'] = 'running'\n",
        "        try:\n",
        "            print(f\"üîß Processing job {jobid} topic:{topic}\")\n",
        "            # 1) generate facts (use safe wrapper)\n",
        "            facts = safe_generate_facts(topic, n=FACTS_COUNT)\n",
        "\n",
        "            # 2) per-fact TTS (Bark -> wav -> mp3)\n",
        "            voice_files = []\n",
        "            for i, fact in enumerate(facts):\n",
        "                wav_path = os.path.join(AUDIO_DIR, f\"{jobid}_fact{i+1}.wav\")\n",
        "                mp3_path = os.path.join(AUDIO_DIR, f\"{jobid}_fact{i+1}.mp3\")\n",
        "                ok = None\n",
        "                if BARK_AVAILABLE:\n",
        "                    ok = synthesize_bark_to_wav(fact, wav_path, voice=BARK_VOICE)\n",
        "                if not ok:\n",
        "                    # fallback to simple gTTS\n",
        "                    from gtts import gTTS\n",
        "                    t = gTTS(text=fact, lang=\"en\")\n",
        "                    t.save(wav_path)\n",
        "                # convert to mp3\n",
        "                wav_to_mp3(wav_path, mp3_path)\n",
        "                voice_files.append(mp3_path)\n",
        "\n",
        "            # 3) download b-roll clips (may be fewer than facts)\n",
        "            brolls = download_brolls_for_topic(topic, count=FACTS_COUNT, max_seconds=8)\n",
        "\n",
        "            # 4) build final video synchronized to per-fact audio\n",
        "            out_file = os.path.join(OUTPUT_DIR, f\"creepy_{jobid}.mp4\")\n",
        "            build_vertical_video_v2(facts, voice_files, brolls, out_file)\n",
        "\n",
        "            jobs[jobid]['status'] = 'done'\n",
        "            jobs[jobid]['result'] = out_file\n",
        "            jobs[jobid]['finished'] = time.time()\n",
        "            print(f\"‚úÖ Job {jobid} finished -> {out_file}\")\n",
        "        except Exception as e:\n",
        "            jobs[jobid]['status'] = 'error'\n",
        "            jobs[jobid]['error'] = str(e)\n",
        "            print(\"‚ùå Worker error:\", e)\n",
        "        finally:\n",
        "            job_q.task_done()\n",
        "\n",
        "# start worker thread (daemon)\n",
        "threading.Thread(target=full_worker, daemon=True).start()\n",
        "\n",
        "# ---- Flask endpoints (enqueue + status + download) ----\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route(\"/generate\", methods=[\"POST\"])\n",
        "def enqueue():\n",
        "    data = request.get_json(force=True, silent=True) or {}\n",
        "    topic = data.get('topic','creepy facts')\n",
        "    jobid = str(uuid.uuid4())[:8]\n",
        "    jobs[jobid] = {\"status\":\"queued\",\"topic\":topic,\"created\":time.time()}\n",
        "    job_q.put((jobid, topic))\n",
        "    return jsonify({\"status\":\"queued\",\"jobid\":jobid,\"poll\":f\"/status/{jobid}\"})\n",
        "\n",
        "@app.route(\"/status/<jobid>\", methods=[\"GET\"])\n",
        "def status(jobid):\n",
        "    info = jobs.get(jobid)\n",
        "    if not info:\n",
        "        return jsonify({\"error\":\"unknown jobid\"}), 404\n",
        "    return jsonify(info)\n",
        "\n",
        "@app.route(\"/download/<jobid>\", methods=[\"GET\"])\n",
        "def download(jobid):\n",
        "    info = jobs.get(jobid)\n",
        "    if not info or info.get(\"status\") != \"done\":\n",
        "        return jsonify({\"error\":\"not ready\"}), 404\n",
        "    path = info.get(\"result\")\n",
        "    if not path or not os.path.exists(path):\n",
        "        return jsonify({\"error\":\"file missing\"}), 404\n",
        "    return send_file(path, mimetype=\"video/mp4\", as_attachment=True, download_name=os.path.basename(path))\n",
        "\n",
        "@app.route(\"/\", methods=[\"GET\"])\n",
        "def root():\n",
        "    return jsonify({\"status\":\"alive\",\"info\":\"Full video queue API. POST /generate with {'topic':'...'}\"})\n",
        "\n",
        "# Start cloudflared tunnel printing (if not already started elsewhere)\n",
        "def start_cloudflared_and_print_local():\n",
        "    try:\n",
        "        cmd = [\"cloudflared\", \"tunnel\", \"--url\", f\"http://localhost:{PORT}\"]\n",
        "        popen = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "        for _ in range(400):\n",
        "            line = popen.stdout.readline()\n",
        "            if not line:\n",
        "                time.sleep(0.1)\n",
        "                continue\n",
        "            print(line.strip())\n",
        "            if \"trycloudflare.com\" in line or \"trycloudflare\" in line:\n",
        "                m = re.search(r'(https?://[^\\s]+trycloudflare[^\\s]*)', line)\n",
        "                public_url = m.group(1) if m else line.strip()\n",
        "                print(\"\\n‚úÖ PUBLIC URL:\", public_url)\n",
        "                print(\"Use this to POST /generate and GET /status/<jobid>\\n\")\n",
        "                break\n",
        "    except Exception as e:\n",
        "        print(\"cloudflared start failed (maybe already running):\", e)\n",
        "\n",
        "# If the Flask server isn't running, start it. If it is, you can ignore.\n",
        "def start_flask_local():\n",
        "    app.run(host='0.0.0.0', port=PORT)\n",
        "\n",
        "# run flask & cloudflared if needed (safe to call)\n",
        "threading.Thread(target=start_flask_local, daemon=True).start()\n",
        "time.sleep(1)\n",
        "threading.Thread(target=start_cloudflared_and_print_local, daemon=True).start()\n",
        "\n",
        "print(\"‚úÖ Full-video worker + endpoints started. POST /generate to queue a job.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "9AIaMLzKXeKo",
        "outputId": "0ed1756f-3943-4afd-f651-b1bb82a2f6db"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-01T17:18:48Z INF Thank you for trying Cloudflare Tunnel. Doing so, without a Cloudflare account, is a quick way to experiment and try it out. However, be aware that these account-less Tunnels have no uptime guarantee, are subject to the Cloudflare Online Services Terms of Use (https://www.cloudflare.com/website-terms/), and Cloudflare reserves the right to investigate your use of Tunnels for violations of such terms. If you intend to use Tunnels in production you should use a pre-created named tunnel by following: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps\n",
            "2025-11-01T17:18:48Z INF Requesting new quick Tunnel on trycloudflare.com...\n",
            "\n",
            "‚úÖ PUBLIC URL: 2025-11-01T17:18:48Z INF Requesting new quick Tunnel on trycloudflare.com...\n",
            "Use this to POST /generate and GET /status/<jobid>\n",
            "\n",
            "Preloading Bark models (may download tens to hundreds MB).\n",
            "Bark preload warning: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n",
            "\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n",
            "\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n",
            "\tWeightsUnpickler error: Unsupported global: GLOBAL numpy.core.multiarray.scalar was not an allowed global by default. Please use `torch.serialization.add_safe_globals([numpy.core.multiarray.scalar])` or the `torch.serialization.safe_globals([numpy.core.multiarray.scalar])` context manager to allowlist this global if you trust this class/function.\n",
            "\n",
            "Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.\n",
            "Bark is available and will be used for TTS.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'draw' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1735216174.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;31m# compute height\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m \u001b[0mbbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtextbbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Ay\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfont\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfont\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0mline_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m10\u001b[0m   \u001b[0;31m# height + padding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'draw' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# üåê CLOUDFLARED TUNNEL SETUP\n",
        "# =========================\n",
        "import subprocess, time, re\n",
        "\n",
        "# Install cloudflared if not already installed\n",
        "!curl -L https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -o cloudflared\n",
        "!chmod +x cloudflared\n",
        "\n",
        "PORT = 5000  # same port as Flask API\n",
        "\n",
        "def start_tunnel():\n",
        "    print(\"Starting Cloudflared tunnel...\")\n",
        "    process = subprocess.Popen([\"./cloudflared\", \"tunnel\", \"--url\", f\"http://localhost:{PORT}\", \"--logfile\", \"cloudflared.log\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "    time.sleep(5)\n",
        "\n",
        "    # read log for the public URL\n",
        "    with open(\"cloudflared.log\") as f:\n",
        "        logs = f.read()\n",
        "        urls = re.findall(r\"https://.*?trycloudflare\\.com\", logs)\n",
        "        if urls:\n",
        "            public_url = urls[-1]\n",
        "            print(\"\\n‚úÖ Tunnel active!\")\n",
        "            print(\"Public API URL:\", public_url)\n",
        "            print(\"\\nPOST to: \" + public_url + \"/generate\")\n",
        "            return public_url\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è Cloudflared didn't return a URL. Restarting...\")\n",
        "            process.kill()\n",
        "            time.sleep(3)\n",
        "            return start_tunnel()\n",
        "\n",
        "public_url = start_tunnel()"
      ],
      "metadata": {
        "id": "uanGla61-1PG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "res = requests.post(\"https://strengthening-cast-rights-declined.trycloudflare.com/generate\", json={\"topic\":\"creepy hospital facts\"})\n",
        "print(res.json())\n",
        "jobid = res.json()[\"jobid\"]"
      ],
      "metadata": {
        "id": "gs3_ElyxPDYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time, requests\n",
        "while True:\n",
        "    r = requests.get(f\"https://strengthening-cast-rights-declined.trycloudflare.com/status/{jobid}\")\n",
        "    print(r.json())\n",
        "    if r.json().get(\"status\") in (\"done\",\"error\"):\n",
        "        break\n",
        "    time.sleep(4)\n"
      ],
      "metadata": {
        "id": "aBPW7mu0PJ6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Single-cell: Full pipeline (facts -> per-fact TTS -> b-roll + music -> vertical video -> save to Google Drive)\n",
        "# Paste & run in Google Colab (Notebook A). Then call generate_and_upload(\"your topic here\").\n",
        "\n",
        "# -------------------- INSTALL / IMPORTS --------------------\n",
        "!pip install -q yt-dlp moviepy Pillow soundfile transformers accelerate git+https://github.com/rhasspy/python-mpv.git >/dev/null\n",
        "!apt-get update -qq && apt-get install -y -qq ffmpeg >/dev/null\n",
        "\n",
        "import os, time, uuid, json, subprocess, threading, math\n",
        "from pathlib import Path\n",
        "from moviepy.editor import VideoFileClip, AudioFileClip, CompositeVideoClip, concatenate_videoclips, ColorClip, ImageClip, CompositeAudioClip, afx\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "\n",
        "# -------------------- CONFIG --------------------\n",
        "BASE_DIR = Path(\"/content/ai_pipeline\")\n",
        "OUTPUT_DIR = BASE_DIR / \"output\"\n",
        "AUDIO_DIR = BASE_DIR / \"audio\"\n",
        "BROLL_DIR = BASE_DIR / \"broll\"\n",
        "FONT_PATH = \"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\"\n",
        "DRIVE_OUT = Path(\"/content/drive/MyDrive/ai_fact_videos\")\n",
        "WIDTH, HEIGHT, FPS = 1080, 1920, 25\n",
        "FACT_COUNT = 5\n",
        "VOICE_PRESET = \"v2/en_speaker_9\"  # Bark preset if Bark available\n",
        "MUSIC_SEARCH = \"dark ambient background music creative commons\"\n",
        "\n",
        "for p in (OUTPUT_DIR, AUDIO_DIR, BROLL_DIR, DRIVE_OUT):\n",
        "    p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# -------------------- OPTIONAL KEYS (set in Colab env or leave empty) --------------------\n",
        "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\", \"\")\n",
        "ELEVEN_API_KEY = os.getenv(\"ELEVEN_API_KEY\", \"\")\n",
        "\n",
        "# -------------------- MOUNT DRIVE --------------------\n",
        "try:\n",
        "    drive.mount('/content/drive', force_remount=False)\n",
        "except Exception as e:\n",
        "    print(\"Drive mount (if needed) error:\", e)\n",
        "\n",
        "# -------------------- TEXT (facts) GENERATOR --------------------\n",
        "# Try Groq/OpenAI-like endpoint if key present, else fallback to small HF model (flan-t5-small).\n",
        "def generate_facts(topic, n=FACT_COUNT):\n",
        "    topic = str(topic)\n",
        "    if GROQ_API_KEY:\n",
        "        try:\n",
        "            import requests\n",
        "            url = \"https://api.groq.com/openai/v1/chat/completions\"\n",
        "            headers = {\"Authorization\": f\"Bearer {GROQ_API_KEY}\", \"Content-Type\": \"application/json\"}\n",
        "            prompt = f\"Generate {n} dark, creepy, one-line facts about {topic}. Each 6-18 words. Return as newline-separated list.\"\n",
        "            data = {\"model\":\"llama-3.1-8b-instant\",\"messages\":[{\"role\":\"user\",\"content\":prompt}],\"max_tokens\":300,\"temperature\":0.8}\n",
        "            r = requests.post(url, headers=headers, json=data, timeout=30)\n",
        "            text = r.json().get(\"choices\",[{}])[0].get(\"message\",{}).get(\"content\",\"\")\n",
        "            lines = [l.strip(\"-‚Ä¢ \").strip() for l in text.splitlines() if l.strip()]\n",
        "            if len(lines) >= n:\n",
        "                return lines[:n]\n",
        "        except Exception as e:\n",
        "            print(\"Groq fetch failed, falling back:\", e)\n",
        "\n",
        "    # Fallback: small HF model local (no heavy download).\n",
        "    try:\n",
        "        from transformers import pipeline\n",
        "        gen = pipeline(\"text2text-generation\", model=\"google/flan-t5-small\", device=-1)\n",
        "        prompt = f\"Write {n} short creepy facts about {topic}. Each 1 sentence, under 18 words. Return as newline separated.\"\n",
        "        out = gen(prompt, max_length=256, do_sample=True, top_p=0.95, num_return_sequences=1)[0]['generated_text']\n",
        "        lines = [l.strip() for l in out.replace(\"\\r\", \"\\n\").split(\"\\n\") if l.strip()]\n",
        "        if len(lines) >= n:\n",
        "            return lines[:n]\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # Final minimal fallback\n",
        "    return [f\"{topic} fact {i+1}\" for i in range(n)]\n",
        "\n",
        "# -------------------- TTS: try Bark local first, else gTTS fallback --------------------\n",
        "BARK_AVAILABLE = False\n",
        "try:\n",
        "    from bark import generate_audio, preload_models, SAMPLE_RATE\n",
        "    try:\n",
        "        preload_models()\n",
        "    except Exception as e:\n",
        "        print(\"Bark preload warning:\", e)\n",
        "    BARK_AVAILABLE = True\n",
        "    print(\"Bark available for TTS.\")\n",
        "except Exception as e:\n",
        "    print(\"Bark not available, will use gTTS fallback.\", e)\n",
        "    BARK_AVAILABLE = False\n",
        "\n",
        "def bark_text_to_wav(text, out_wav, voice=VOICE_PRESET):\n",
        "    try:\n",
        "        wav = generate_audio(text=text, history_prompt=voice)\n",
        "        arr = np.array(wav)\n",
        "        sf.write(out_wav, arr, SAMPLE_RATE)\n",
        "        return out_wav\n",
        "    except Exception as e:\n",
        "        print(\"Bark synth failed:\", e)\n",
        "        return None\n",
        "\n",
        "def gtts_text_to_wav(text, out_wav):\n",
        "    try:\n",
        "        from gtts import gTTS\n",
        "        t = gTTS(text=text, lang=\"en\")\n",
        "        t.save(str(out_wav))\n",
        "        return str(out_wav)\n",
        "    except Exception as e:\n",
        "        print(\"gTTS failed:\", e)\n",
        "        return None\n",
        "\n",
        "def ensure_mp3(in_wav, out_mp3):\n",
        "    try:\n",
        "        cmd = [\"ffmpeg\", \"-y\", \"-i\", str(in_wav), \"-codec:a\", \"libmp3lame\", \"-qscale:a\", \"2\", str(out_mp3)]\n",
        "        subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "        return out_mp3\n",
        "    except Exception as e:\n",
        "        print(\"ffmpeg convert failed:\", e)\n",
        "        return None\n",
        "\n",
        "def synthesize_fact_audio(fact_text, out_prefix, idx):\n",
        "    wav = AUDIO_DIR / f\"{out_prefix}_fact{idx+1}.wav\"\n",
        "    mp3 = AUDIO_DIR / f\"{out_prefix}_fact{idx+1}.mp3\"\n",
        "    ok = None\n",
        "    if BARK_AVAILABLE:\n",
        "        ok = bark_text_to_wav(fact_text, str(wav))\n",
        "    if not ok:\n",
        "        ok = gtts_text_to_wav(fact_text, str(wav))\n",
        "    if not ok:\n",
        "        raise RuntimeError(\"No TTS available\")\n",
        "    ensure_mp3(str(wav), str(mp3))\n",
        "    return str(mp3)\n",
        "\n",
        "# -------------------- Download b-roll (yt-dlp search, CC) --------------------\n",
        "def download_brolls(topic, count=FACT_COUNT, max_seconds=8):\n",
        "    clips = []\n",
        "    queries = [f\"{topic} cinematic\", \"dark cinematic fog\", \"abandoned building cinematic\", f\"{topic} b-roll\"]\n",
        "    for q in queries:\n",
        "        if len(clips) >= count: break\n",
        "        try:\n",
        "            out_template = str(BROLL_DIR / \"clip_%(id)s.%(ext)s\")\n",
        "            cmd = [\"yt-dlp\", f\"ytsearch1:{q} creative commons\", \"--no-playlist\", \"--format\", \"mp4\", \"--output\", out_template]\n",
        "            subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "            # find newest clip file\n",
        "            candidates = sorted([p for p in BROLL_DIR.iterdir() if p.name.startswith(\"clip_\") and p.suffix in (\".mp4\", \".m4v\")])\n",
        "            if not candidates: continue\n",
        "            src = candidates[-1]\n",
        "            # trim\n",
        "            dest = BROLL_DIR / (src.stem + \"_trim.mp4\")\n",
        "            clip = VideoFileClip(str(src))\n",
        "            dur = min(max_seconds, clip.duration)\n",
        "            clip.subclip(0, dur).write_videofile(str(dest), fps=FPS, codec=\"libx264\", audio_codec=\"aac\", threads=2, verbose=False, logger=None)\n",
        "            clip.close()\n",
        "            clips.append(str(dest))\n",
        "        except Exception as e:\n",
        "            print(\"b-roll fetch error:\", e)\n",
        "            continue\n",
        "    # if not enough clips, use color fallback repeated\n",
        "    while len(clips) < count:\n",
        "        clips.append(None)\n",
        "    return clips[:count]\n",
        "\n",
        "# -------------------- Download ambient music track --------------------\n",
        "def download_ambient(max_seconds=120):\n",
        "    try:\n",
        "        out_template = str(OUTPUT_DIR / \"music_%(id)s.%(ext)s\")\n",
        "        cmd = [\"yt-dlp\", f\"ytsearch1:{MUSIC_SEARCH}\", \"--no-playlist\", \"--format\", \"bestaudio\", \"--output\", out_template]\n",
        "        subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "        candidates = sorted([p for p in OUTPUT_DIR.iterdir() if p.name.startswith(\"music_\")])\n",
        "        if not candidates:\n",
        "            return None\n",
        "        src = candidates[-1]\n",
        "        trimmed = OUTPUT_DIR / (src.stem + \"_trim.mp3\")\n",
        "        cmd2 = [\"ffmpeg\", \"-y\", \"-i\", str(src), \"-t\", str(max_seconds), \"-vn\", \"-acodec\", \"libmp3lame\", \"-qscale:a\", \"4\", str(trimmed)]\n",
        "        subprocess.run(cmd2, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "        return str(trimmed)\n",
        "    except Exception as e:\n",
        "        print(\"music download failed:\", e)\n",
        "        return None\n",
        "\n",
        "# -------------------- Text -> Image (PIL) helper (auto-wrap, uses textbbox) --------------------\n",
        "def render_text_image(text, out_image_path, width=WIDTH, padding=80, font_path=FONT_PATH, font_size=56, align=\"center\"):\n",
        "    try:\n",
        "        font = ImageFont.truetype(font_path, font_size)\n",
        "    except Exception:\n",
        "        font = ImageFont.load_default()\n",
        "    # temporary draw for measuring\n",
        "    temp_img = Image.new(\"RGBA\", (width, 2000), (0,0,0,0))\n",
        "    temp_draw = ImageDraw.Draw(temp_img)\n",
        "    words = text.split()\n",
        "    lines = []\n",
        "    cur = \"\"\n",
        "    for w in words:\n",
        "        test = (cur + \" \" + w).strip()\n",
        "        bbox = temp_draw.textbbox((0,0), test, font=font)\n",
        "        wsize = bbox[2] - bbox[0]\n",
        "        if wsize > (width - 2*padding):\n",
        "            if cur:\n",
        "                lines.append(cur)\n",
        "            cur = w\n",
        "        else:\n",
        "            cur = test\n",
        "    if cur:\n",
        "        lines.append(cur)\n",
        "    # compute height\n",
        "    bbox = temp_draw.textbbox((0,0), \"Ay\", font=font)\n",
        "    line_h = (bbox[3] - bbox[1]) + 10\n",
        "    img_h = padding + line_h * len(lines) + padding\n",
        "    img = Image.new(\"RGBA\", (width, max(img_h, 240)), (0,0,0,0))\n",
        "    draw = ImageDraw.Draw(img)\n",
        "    y = padding//2\n",
        "    for line in lines:\n",
        "        bbox = draw.textbbox((0,0), line, font=font)\n",
        "        w = bbox[2] - bbox[0]\n",
        "        if align==\"center\":\n",
        "            x = (width - w)//2\n",
        "        elif align==\"left\":\n",
        "            x = padding\n",
        "        else:\n",
        "            x = width - padding - w\n",
        "        draw.text((x, y), line, font=font, fill=(255,255,255,255))\n",
        "        y += line_h\n",
        "    img.save(out_image_path)\n",
        "    return out_image_path\n",
        "\n",
        "# -------------------- Build vertical video synchronized to per-fact audio --------------------\n",
        "def build_vertical(facts, voice_mp3s, brolls, music_path, out_path, username=\"darktruths.hub007\"):\n",
        "    clips = []\n",
        "    music_clip = AudioFileClip(music_path).volumex(0.12) if music_path else None\n",
        "    for i, fact in enumerate(facts):\n",
        "        # choose b-roll or fallback color\n",
        "        b = brolls[i] if i < len(brolls) else None\n",
        "        if b:\n",
        "            try:\n",
        "                bg = VideoFileClip(b).resize(height=HEIGHT)\n",
        "                if bg.w < WIDTH: bg = bg.resize(width=WIDTH)\n",
        "            except Exception:\n",
        "                bg = ColorClip((WIDTH, HEIGHT), color=(8,8,12)).set_duration(5)\n",
        "        else:\n",
        "            bg = ColorClip((WIDTH, HEIGHT), color=(8,8,12)).set_duration(5)\n",
        "        # audio duration from mp3\n",
        "        a = AudioFileClip(voice_mp3s[i])\n",
        "        dur = a.duration + 0.4\n",
        "        bg = bg.subclip(0, min(dur, bg.duration)) if bg.duration>dur else bg.set_duration(dur)\n",
        "        # render text image\n",
        "        txt_img = OUTPUT_DIR / f\"text_{uuid.uuid4().hex[:6]}_{i}.png\"\n",
        "        render_text_image(fact, str(txt_img), width=WIDTH, font_size=56)\n",
        "        txt_clip = ImageClip(str(txt_img)).set_duration(dur).set_position((\"center\", int(HEIGHT*0.12)))\n",
        "        # mix voice + music\n",
        "        if music_clip:\n",
        "            try:\n",
        "                music_sub = music_clip.subclip(0, a.duration).volumex(0.12)\n",
        "                final_audio = CompositeAudioClip([music_sub, a])\n",
        "            except Exception:\n",
        "                final_audio = a\n",
        "        else:\n",
        "            final_audio = a\n",
        "        clip = CompositeVideoClip([bg, txt_clip], size=(WIDTH, HEIGHT)).set_duration(dur).set_audio(final_audio)\n",
        "        clips.append(clip)\n",
        "    final = concatenate_videoclips(clips, method=\"compose\")\n",
        "    # watermark\n",
        "    wm_img = OUTPUT_DIR / \"wm.png\"\n",
        "    render_text_image(username, str(wm_img), width=600, font_size=28)\n",
        "    wm = ImageClip(str(wm_img)).set_duration(final.duration).set_position((\"right\",\"bottom\")).set_opacity(0.85)\n",
        "    final = CompositeVideoClip([final, wm])\n",
        "    final.write_videofile(str(out_path), fps=FPS, codec=\"libx264\", audio_codec=\"aac\", threads=4)\n",
        "    return str(out_path)\n",
        "\n",
        "# -------------------- Main function: generate and upload --------------------\n",
        "def generate_and_upload(topic):\n",
        "    task_id = uuid.uuid4().hex[:8]\n",
        "    print(\"-> Generating facts...\")\n",
        "    facts = generate_facts(topic, n=FACT_COUNT)\n",
        "    print(\"Facts:\", facts)\n",
        "    # synthesize audio per fact\n",
        "    voice_files = []\n",
        "    for i, fact in enumerate(facts):\n",
        "        print(\"TTS fact\", i+1)\n",
        "        mp3 = synthesize_fact_audio(fact, task_id, i)\n",
        "        voice_files.append(mp3)\n",
        "    # download b-rolls\n",
        "    print(\"Downloading b-roll clips...\")\n",
        "    brolls = download_brolls(topic, count=FACT_COUNT)\n",
        "    print(\"b-rolls:\", brolls)\n",
        "    # download music\n",
        "    print(\"Downloading ambient music...\")\n",
        "    music = download_ambient(max_seconds=120)\n",
        "    print(\"music:\", music)\n",
        "    # build final video\n",
        "    out_file = OUTPUT_DIR / f\"video_{task_id}.mp4\"\n",
        "    print(\"Building video (this may take a few minutes)...\")\n",
        "    build_vertical(facts, voice_files, brolls, music, out_file, username=os.getenv(\"USERNAME_WM\",\"darktruths.hub007\"))\n",
        "    # upload to Drive (copy file)\n",
        "    DRIVE_OUT.mkdir(parents=True, exist_ok=True)\n",
        "    dest = DRIVE_OUT / out_file.name\n",
        "    try:\n",
        "        subprocess.run([\"cp\", str(out_file), str(dest)], check=True)\n",
        "        print(\"Saved to Google Drive:\", dest)\n",
        "    except Exception as e:\n",
        "        print(\"Failed to copy to Drive:\", e)\n",
        "    return {\"task_id\": task_id, \"drive_path\": str(dest), \"local_path\": str(out_file), \"facts\": facts}\n",
        "\n",
        "# -------------------- USAGE --------------------\n",
        "print(\"Ready. Call generate_and_upload('your topic here') to create a video and save it to your Google Drive.\")\n"
      ],
      "metadata": {
        "id": "yUBerisQ9M6i",
        "outputId": "45ad8e4a-6445-4091-b18c-7ad144e01f14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m√ó\u001b[0m \u001b[32mgit clone --\u001b[0m\u001b[32mfilter\u001b[0m\u001b[32m=\u001b[0m\u001b[32mblob\u001b[0m\u001b[32m:none --quiet \u001b[0m\u001b[4;32mhttps://github.com/rhasspy/python-mpv.git\u001b[0m\u001b[32m \u001b[0m\u001b[32m/tmp/\u001b[0m\u001b[32mpip-req-build-_3e_x0e6\u001b[0m did not run successfully.\n",
            "  \u001b[31m‚îÇ\u001b[0m exit code: \u001b[1;36m128\u001b[0m\n",
            "  \u001b[31m‚ï∞‚îÄ>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "\n",
            "\u001b[31m√ó\u001b[0m \u001b[32mgit clone --\u001b[0m\u001b[32mfilter\u001b[0m\u001b[32m=\u001b[0m\u001b[32mblob\u001b[0m\u001b[32m:none --quiet \u001b[0m\u001b[4;32mhttps://github.com/rhasspy/python-mpv.git\u001b[0m\u001b[32m \u001b[0m\u001b[32m/tmp/\u001b[0m\u001b[32mpip-req-build-_3e_x0e6\u001b[0m did not run successfully.\n",
            "\u001b[31m‚îÇ\u001b[0m exit code: \u001b[1;36m128\u001b[0m\n",
            "\u001b[31m‚ï∞‚îÄ>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Drive mount (if needed) error: Mountpoint must not already contain files\n",
            "Bark not available, will use gTTS fallback. No module named 'bark'\n",
            "Ready. Call generate_and_upload('your topic here') to create a video and save it to your Google Drive.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "l01c01_introduction_to_colab_and_python.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}